{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ========= USER CONFIG =========\n",
    "# Use absolute paths\n",
    "# You need to load your local fastText model\n",
    "RESULT_DIR = Path(\"/home/zhong/test-folder/lang_trans/outputs/llama2-7b_dims400_para/mt\")\n",
    "LID_PATH   = Path(\"/home/zhong/fasttext/lid.176.bin\")\n",
    "\n",
    "TARGET_LANGS = [\"zh\", \"fr\", \"es\", \"de\", \"ja\"]   # or [\"all\"]\n",
    "\n",
    "DATA_SOURCES = [\"all\"]\n",
    "\n",
    "LID_THRESHOLD = 0.50\n",
    "\n",
    "ENABLE_EN2X = True\n",
    "ENABLE_X2EN = False\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcfeab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import sacrebleu\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Load fastText lid model\n",
    "lid = fasttext.load_model(str(LID_PATH))\n",
    "\n",
    "_bleu_cache = {}\n",
    "def get_bleu_metric(lang: str):\n",
    "    if lang not in _bleu_cache:\n",
    "        if lang == \"zh\":\n",
    "            _bleu_cache[lang] = sacrebleu.BLEU(tokenize=\"zh\", effective_order=True)\n",
    "        elif lang == \"ja\":\n",
    "            _bleu_cache[lang] = sacrebleu.BLEU(tokenize=\"ja-mecab\", effective_order=True)\n",
    "        else:\n",
    "            _bleu_cache[lang] = sacrebleu.BLEU(effective_order=True)\n",
    "    return _bleu_cache[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b8e2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en->x: en.control.<layer>.<coeff>.{lang}.json or .jsonl\n",
    "EN2X_RE = re.compile(\n",
    "    r\"^en\\.control\\.(\\d{1,2})\\.(\\d+)\\.(\\d{2})\\.(zh|ja|fr|es|de|en|ko|tr|id|ar)\\.(jsonl|json)$\"\n",
    ")\n",
    "\n",
    "# x->en: {lang}.control.<layer>.<coeff>.en.jsonl (你现在的新命名)\n",
    "X2EN_RE = re.compile(\n",
    "    r\"^(zh|ja|fr|es|de|en|ko|tr|id|ar)\\.control\\.(\\d{1,2})\\.(\\d+)\\.(\\d{2})\\.en\\.(jsonl|json)$\"\n",
    ")\n",
    "\n",
    "ALL_LANGS_ALLOWED = [\"zh\",\"ja\",\"fr\",\"es\",\"de\",\"en\",\"ko\",\"tr\",\"id\",\"ar\"]\n",
    "\n",
    "def norm_langs(langs):\n",
    "    langs = [l.lower() for l in langs]\n",
    "    if \"all\" in langs:\n",
    "        return ALL_LANGS_ALLOWED[:]\n",
    "    return [l for l in langs if l in ALL_LANGS_ALLOWED]\n",
    "\n",
    "def norm_sources(srcs):\n",
    "    srcs = [s.lower() for s in srcs]\n",
    "    if \"all\" in srcs:\n",
    "        return None\n",
    "    return set(srcs)\n",
    "\n",
    "TARGET_LANGS_NORM = norm_langs(TARGET_LANGS)\n",
    "DATA_SOURCES_NORM = norm_sources(DATA_SOURCES)\n",
    "\n",
    "def parse_filename(fp_name: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      direction: \"en2x\" or \"x2en\"\n",
    "      layer: int\n",
    "      coeff: float (rounded to 0.01 exactly as in filename)\n",
    "      src_lang: str\n",
    "      tgt_lang: str\n",
    "    or None if not matched.\n",
    "    \"\"\"\n",
    "    if ENABLE_EN2X:\n",
    "        m = EN2X_RE.match(fp_name)\n",
    "        if m:\n",
    "            layer = int(m.group(1))\n",
    "            coeff_str = f\"{m.group(2)}.{m.group(3)}\"\n",
    "            coeff = float(Decimal(coeff_str).quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP))\n",
    "            tgt_lang = m.group(4)\n",
    "            return (\"en2x\", layer, coeff, \"en\", tgt_lang)\n",
    "\n",
    "    if ENABLE_X2EN:\n",
    "        m = X2EN_RE.match(fp_name)\n",
    "        if m:\n",
    "            src_lang = m.group(1)\n",
    "            layer = int(m.group(2))\n",
    "            coeff_str = f\"{m.group(3)}.{m.group(4)}\"\n",
    "            coeff = float(Decimal(coeff_str).quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP))\n",
    "            return (\"x2en\", layer, coeff, src_lang, \"en\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bdc41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 files under /mnt/zamia/zhong/test-folder/lang_trans/outputs/llama2-7b_dims400_para/mt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d8c758e63a4deeabac3d204f7ed4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers   : 18 .. 18 (count=1)\n",
      "Coeffs   : 0.4 .. 0.4 (unique=1)\n",
      "Entries  : 5\n"
     ]
    }
   ],
   "source": [
    "# Scan result files\n",
    "RESULT_DIR = RESULT_DIR.expanduser().resolve()\n",
    "paths = list(RESULT_DIR.rglob(\"*.json*\"))  # json / jsonl\n",
    "print(f\"Found {len(paths)} files under {RESULT_DIR}\")\n",
    "\n",
    "entries = []  # (fp, direction, layer, coeff, src_lang, tgt_lang)\n",
    "layer_set = set()\n",
    "coeff_set = set()\n",
    "\n",
    "for fp in tqdm(paths, desc=\"Scanning\"):\n",
    "    parsed = parse_filename(fp.name)\n",
    "    if not parsed:\n",
    "        continue\n",
    "    direction, layer, coeff, src_lang, tgt_lang = parsed\n",
    "\n",
    "    output_lang = tgt_lang\n",
    "    if output_lang not in TARGET_LANGS_NORM:\n",
    "        continue\n",
    "\n",
    "    entries.append((fp, direction, layer, coeff, src_lang, tgt_lang))\n",
    "    layer_set.add(layer)\n",
    "    coeff_set.add(coeff)\n",
    "\n",
    "if not entries:\n",
    "    raise ValueError(\"No matched files. Check RESULT_DIR / patterns / TARGET_LANGS.\")\n",
    "\n",
    "LAYERS = sorted(layer_set)\n",
    "COEFFS = sorted(coeff_set)\n",
    "\n",
    "print(f\"Layers   : {LAYERS[0]} .. {LAYERS[-1]} (count={len(LAYERS)})\")\n",
    "print(f\"Coeffs   : {COEFFS[0]} .. {COEFFS[-1]} (unique={len(COEFFS)})\")\n",
    "print(f\"Entries  : {len(entries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac21e2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5207a5827c43419cb5ab2a04d3f85aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aggregating:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC_mat shape: (1, 1) BLEU_mat shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# stats[(layer, coeff)] = [total, success, bleu_sum_success, bleu_cnt_success]\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "stats = {(L, C): [0, 0, 0.0, 0] for L in LAYERS for C in COEFFS}\n",
    "\n",
    "def iter_samples(fp: Path):\n",
    "    \"\"\"\n",
    "    Yield per-sample dict from either:\n",
    "      - JSONL: one JSON object per line\n",
    "      - JSON : list[dict] OR dict containing a list (results/data) OR single dict\n",
    "    \"\"\"\n",
    "    suffix = fp.suffix.lower()\n",
    "\n",
    "    if suffix == \".jsonl\":\n",
    "        with fp.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                yield json.loads(line)\n",
    "        return\n",
    "\n",
    "    if suffix == \".json\":\n",
    "        with fp.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            obj = json.load(f)\n",
    "\n",
    "        if isinstance(obj, list):\n",
    "            for x in obj:\n",
    "                if isinstance(x, dict):\n",
    "                    yield x\n",
    "            return\n",
    "\n",
    "        if isinstance(obj, dict):\n",
    "            # common containers\n",
    "            for k in (\"results\", \"data\", \"samples\", \"items\"):\n",
    "                if k in obj and isinstance(obj[k], list):\n",
    "                    for x in obj[k]:\n",
    "                        if isinstance(x, dict):\n",
    "                            yield x\n",
    "                    return\n",
    "            # fallback: treat as a single sample dict\n",
    "            yield obj\n",
    "        return\n",
    "\n",
    "    raise ValueError(f\"Unsupported file suffix: {fp.suffix}\")\n",
    "\n",
    "\n",
    "def fasttext_lang_and_prob(text: str):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    labels, probs = lid.predict(text[:4096])\n",
    "    pred_lang = labels[0].replace(\"__label__\", \"\")\n",
    "    prob = float(probs[0])\n",
    "    return pred_lang, prob\n",
    "\n",
    "for fp, direction, layer, coeff, src_lang, tgt_lang in tqdm(entries, desc=\"Aggregating\"):\n",
    "    key = (layer, coeff)\n",
    "    bleu_metric = get_bleu_metric(tgt_lang)\n",
    "\n",
    "    for js in iter_samples(fp):\n",
    "        # 数据源过滤（如果你文件里有 data 字段）\n",
    "        if DATA_SOURCES_NORM is not None:\n",
    "            if js.get(\"data\") not in DATA_SOURCES_NORM:\n",
    "                continue\n",
    "\n",
    "        pred_lang, prob = fasttext_lang_and_prob(js.get(\"trans\", \"\"))\n",
    "        is_lang_ok = (pred_lang == tgt_lang) and (prob >= LID_THRESHOLD)\n",
    "\n",
    "        stats[key][0] += 1  # total\n",
    "\n",
    "        if is_lang_ok:\n",
    "            stats[key][1] += 1  # success\n",
    "            hyp = js.get(\"trans\", \"\")\n",
    "            ref = js.get(\"refer\", \"\")\n",
    "            score = bleu_metric.sentence_score(hyp, [ref]).score\n",
    "            stats[key][2] += score\n",
    "            stats[key][3] += 1\n",
    "\n",
    "            # 数据源过滤（如果你文件里有 data 字段）\n",
    "            if DATA_SOURCES_NORM is not None:\n",
    "                if js.get(\"data\") not in DATA_SOURCES_NORM:\n",
    "                    continue\n",
    "\n",
    "            # 语言识别 + 阈值成功判定\n",
    "            pred_lang, prob = fasttext_lang_and_prob(js.get(\"trans\", \"\"))\n",
    "            is_lang_ok = (pred_lang == tgt_lang) and (prob >= LID_THRESHOLD)\n",
    "\n",
    "            stats[key][0] += 1  # total\n",
    "\n",
    "            if is_lang_ok:\n",
    "                stats[key][1] += 1  # success\n",
    "\n",
    "                # BLEU 只在成功样本上累计\n",
    "                hyp = js.get(\"trans\", \"\")\n",
    "                ref = js.get(\"refer\", \"\")\n",
    "                score = bleu_metric.sentence_score(hyp, [ref]).score\n",
    "                stats[key][2] += score\n",
    "                stats[key][3] += 1\n",
    "\n",
    "# build matrices\n",
    "H, W = len(LAYERS), len(COEFFS)\n",
    "ACC_mat = np.zeros((H, W), dtype=np.float32)\n",
    "BLEU_mat = np.zeros((H, W), dtype=np.float32)\n",
    "COMB_mat = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "row_index = {L: i for i, L in enumerate(LAYERS)}\n",
    "col_index = {C: j for j, C in enumerate(COEFFS)}\n",
    "\n",
    "for (L, C), (tot, suc, bleu_sum, bleu_cnt) in stats.items():\n",
    "    i, j = row_index[L], col_index[C]\n",
    "    acc = suc / tot if tot else 0.0\n",
    "    bleu = bleu_sum / bleu_cnt if bleu_cnt else 0.0  # success-only average\n",
    "    comb = acc * bleu if (tot and bleu_cnt) else 0.0\n",
    "\n",
    "    ACC_mat[i, j] = acc\n",
    "    BLEU_mat[i, j] = bleu\n",
    "    COMB_mat[i, j] = comb\n",
    "\n",
    "print(\"ACC_mat shape:\", ACC_mat.shape, \"BLEU_mat shape:\", BLEU_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw heatmap and 3D surface\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import FormatStrFormatter, FuncFormatter\n",
    "\n",
    "X_coeff, Y_layer = np.meshgrid(np.array(COEFFS, dtype=float), np.array(LAYERS, dtype=float))\n",
    "\n",
    "def plot_surface_paper(X, Y, Z, zlabel=\"ACC\", cmap=\"viridis\", view=(28, 230), figsize=(7.9, 3.6)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    gs = GridSpec(1, 2, figure=fig, width_ratios=[1.5, 1.0])\n",
    "\n",
    "    # 3D surface\n",
    "    ax3d = fig.add_subplot(gs[0, 0], projection=\"3d\")\n",
    "    surf = ax3d.plot_surface(X, Y, Z, cmap=cmap, linewidth=0, antialiased=True)\n",
    "    ax3d.set_proj_type(\"ortho\")\n",
    "    ax3d.view_init(elev=view[0], azim=view[1])\n",
    "    ax3d.set_box_aspect((1.25, 1.0, 0.7))\n",
    "    ax3d.set_xlabel(r\"$\\alpha$\")\n",
    "    ax3d.set_ylabel(\"Layer\")\n",
    "    ax3d.set_zlabel(zlabel)\n",
    "\n",
    "    for a in (ax3d.xaxis, ax3d.yaxis, ax3d.zaxis):\n",
    "        a.pane.fill = False\n",
    "        a.pane.set_edgecolor(\"white\")\n",
    "\n",
    "    cbar = fig.colorbar(surf, ax=ax3d, shrink=0.80, pad=0.06)\n",
    "    cbar.set_label(zlabel)\n",
    "\n",
    "    # Heatmap (aligned)\n",
    "    ax2d = fig.add_subplot(gs[0, 1])\n",
    "    xs = np.unique(X.ravel())\n",
    "    ys = np.unique(Y.ravel())\n",
    "    dx = np.diff(xs).mean() if len(xs) > 1 else 1.0\n",
    "    dy = np.diff(ys).mean() if len(ys) > 1 else 1.0\n",
    "    extent = (xs[0]-dx/2, xs[-1]+dx/2, ys[0]-dy/2, ys[-1]+dy/2)\n",
    "\n",
    "    im = ax2d.imshow(\n",
    "        Z,\n",
    "        origin=\"lower\",\n",
    "        aspect=\"auto\",\n",
    "        cmap=cmap,\n",
    "        extent=extent,\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "\n",
    "    Xc, Yc = np.meshgrid(xs, ys)\n",
    "    cs = ax2d.contour(\n",
    "        Xc, Yc, Z,\n",
    "        colors=\"k\",\n",
    "        linewidths=0.6,\n",
    "        alpha=0.35,\n",
    "        levels=7,\n",
    "    )\n",
    "    ax2d.clabel(cs, inline=True, fontsize=8, fmt=\"%.2f\")\n",
    "\n",
    "    ax2d.set_xlabel(r\"Scaling Coefficient $\\alpha$\")\n",
    "    ax2d.set_ylabel(\"Layer\")\n",
    "\n",
    "    # optional: y tick shows 1-indexed layer\n",
    "    ax2d.yaxis.set_major_formatter(FuncFormatter(lambda y, pos: f\"{int(round(y))+1}\"))\n",
    "\n",
    "    fig.subplots_adjust(left=0.1, right=0.98, wspace=0.25)\n",
    "    plt.show()\n",
    "\n",
    "plot_surface_paper(X_coeff, Y_layer, ACC_mat, zlabel=\"ACC\")\n",
    "plot_surface_paper(X_coeff, Y_layer, BLEU_mat, zlabel=\"BLEU (success-only)\")\n",
    "plot_surface_paper(X_coeff, Y_layer, COMB_mat, zlabel=\"ACC*BLEU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f14e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Global Best (by ACC*BLEU) ===\n",
      "Layer: 18\n",
      "Strength: 0.40\n",
      "ACC: 0.9954  (2378/2389)\n",
      "BLEU (success-only): 15.5329  (count=2378)\n",
      "ACC*BLEU: 15.4614\n"
     ]
    }
   ],
   "source": [
    "# Report the best (layer, strength) by ACC*BLEU\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "def _fmt(x, nd=4):\n",
    "    return float(Decimal(str(x)).quantize(Decimal(\"0.\" + \"0\"*nd), rounding=ROUND_HALF_UP))\n",
    "\n",
    "best = {\n",
    "    \"layer\": None,\n",
    "    \"strength\": None,\n",
    "    \"acc\": 0.0,\n",
    "    \"bleu_success\": 0.0,\n",
    "    \"a_times_b\": -1.0,\n",
    "    \"total\": 0,\n",
    "    \"correct\": 0,\n",
    "    \"bleu_cnt\": 0,\n",
    "}\n",
    "\n",
    "for (layer, strength), (total, correct, bleu_sum, bleu_cnt) in stats.items():\n",
    "    if total == 0:\n",
    "        continue\n",
    "    acc = correct / total\n",
    "    bleu_success = (bleu_sum / bleu_cnt) if bleu_cnt > 0 else 0.0\n",
    "    a_times_b = acc * bleu_success  # success-only BLEU\n",
    "    if a_times_b > best[\"a_times_b\"]:\n",
    "        best.update({\n",
    "            \"layer\": layer,\n",
    "            \"strength\": strength,\n",
    "            \"acc\": acc,\n",
    "            \"bleu_success\": bleu_success,\n",
    "            \"a_times_b\": a_times_b,\n",
    "            \"total\": total,\n",
    "            \"correct\": correct,\n",
    "            \"bleu_cnt\": bleu_cnt,\n",
    "        })\n",
    "\n",
    "print(\"=== Global Best (by ACC*BLEU) ===\")\n",
    "print(f\"Layer: {best['layer']}\")\n",
    "print(f\"Strength: {best['strength']:.2f}\")\n",
    "print(f\"ACC: {_fmt(best['acc'], 4)}  ({best['correct']}/{best['total']})\")\n",
    "print(f\"BLEU (success-only): {_fmt(best['bleu_success'], 4)}  (count={best['bleu_cnt']})\")\n",
    "print(f\"ACC*BLEU: {_fmt(best['a_times_b'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f32f782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query Result ===\n",
      "Layer: 18\n",
      "Strength: 0.40\n",
      "ACC: 0.9954  (2378/2389)\n",
      "BLEU (success-only): 15.5329  (count=2378)\n",
      "ACC*BLEU: 15.4614\n"
     ]
    }
   ],
   "source": [
    "# Report for specific (layer, strength) you want\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "# ===== user inputs =====\n",
    "QUERY_LAYER = 18\n",
    "QUERY_STRENGTH = 0.40  # e.g., 0.80 / 1.00 / 1.20 ...\n",
    "# =======================\n",
    "\n",
    "def quantize_strength(x: float) -> float:\n",
    "    return float(Decimal(str(x)).quantize(Decimal(\"0.01\"), rounding=ROUND_HALF_UP))\n",
    "\n",
    "layer = int(QUERY_LAYER)\n",
    "strength = quantize_strength(float(QUERY_STRENGTH))\n",
    "\n",
    "key = (layer, strength)\n",
    "if key not in stats:\n",
    "    print(f\"[Not found] (layer={layer}, strength={strength:.2f}) not in stats.\")\n",
    "    print(\"Hint: available layers range:\", (min(LAYERS), max(LAYERS)))\n",
    "    print(\"Hint: strength examples:\", STRENGTHS[:5], \"...\", STRENGTHS[-5:])\n",
    "else:\n",
    "    total, correct, bleu_sum, bleu_cnt = stats[key]\n",
    "    acc = (correct / total) if total else 0.0\n",
    "    bleu_success = (bleu_sum / bleu_cnt) if bleu_cnt else 0.0\n",
    "    a_times_b = acc * bleu_success\n",
    "\n",
    "    def _fmt(x, nd=4):\n",
    "        return float(Decimal(str(x)).quantize(Decimal(\"0.\" + \"0\"*nd), rounding=ROUND_HALF_UP))\n",
    "\n",
    "    print(\"=== Query Result ===\")\n",
    "    print(f\"Layer: {layer}\")\n",
    "    print(f\"Strength: {strength:.2f}\")\n",
    "    print(f\"ACC: {_fmt(acc, 4)}  ({correct}/{total})\")\n",
    "    print(f\"BLEU (success-only): {_fmt(bleu_success, 4)}  (count={bleu_cnt})\")\n",
    "    print(f\"ACC*BLEU: {_fmt(a_times_b, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dapo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
